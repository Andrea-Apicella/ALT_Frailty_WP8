{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluating models on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wp8.pre_processing.utils import listdir_nohidden_sorted as lsdir\n",
    "from tqdm.notebook import tqdm\n",
    "from wp8.pre_processing.generators import TimeSeriesGenerator as TSG\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %env WANDB_API_KEY=$a22c5c63cb14ecd62db2141ec9ca69d588a6483e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"../outputs/dataset/features/\"\n",
    "dataset_path = \"../outputs/dataset/dataset/\"\n",
    "\n",
    "#load features\n",
    "all_features = []\n",
    "all_features_paths = lsdir(features_path)[0:2]\n",
    "for _, feature_file in enumerate(tqdm(all_features_paths)):\n",
    "  with np.load(feature_file) as features:\n",
    "      all_features.append(features[\"arr_0\"])\n",
    "      \n",
    "all_features=np.concatenate(all_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for _,filename in enumerate(tqdm(lsdir(dataset_path)[0:2])):\n",
    "  df = pd.read_csv(filename, index_col=0)\n",
    "  dfs.append(df)\n",
    "\n",
    "dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape, all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dataset[\"frame_name\"]\n",
    "cams = []\n",
    "for name in names:\n",
    "  cams.append(int(name[-6]))\n",
    "\n",
    "dataset[\"cams\"] = pd.Series(cams)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"features\"] = pd.Series(all_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"features\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count samples per label\n",
    "dataset[\"micro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "encoded_labels = le.fit_transform(dataset[\"micro_labels\"])\n",
    "n_labels = len(np.unique(encoded_labels))\n",
    "print(\"n_labels: \", n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len = int(dataset.shape[0] * 0.7)\n",
    "X_train = np.array(dataset[\"features\"][0:len].tolist())\n",
    "X_test = np.array(dataset[\"features\"][len:].tolist())\n",
    "\n",
    "y_train = encoded_labels[0:len]\n",
    "y_test = encoded_labels[len:]\n",
    "\n",
    "cams_train = dataset[\"cams\"][0:len]\n",
    "cams_test = dataset[\"cams\"][len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project = \"WP8\",\n",
    "                 config = {\n",
    "                   \"epochs\": 1,\n",
    "                    \"sequence_length\": 32,\n",
    "                    \"num_features\": 2048,\n",
    "                    \"batch_size\": 32,\n",
    "                    \"sliding_window_stride\": 20,\n",
    "                   \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                   \"architecture\": \"LSTM\",\n",
    "                   \"dataset\": \"single_file\",\n",
    "                 })\n",
    "config = wandb.config\n",
    "\n",
    "train_gen = TSG(X=X_train, y = y_train, num_features=config.num_features, cams=cams_train.tolist(), batch_size = config.batch_size, stride=config.sliding_window_stride, seq_len = config.sequence_length)\n",
    "\n",
    "test_gen = TSG(X=X_test, y = y_test, cams=cams_test.tolist(), num_features=config.num_features, batch_size = config.batch_size, stride=config.sliding_window_stride, seq_len = config.sequence_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(20, config.num_features)))\n",
    "model.add(Dense(n_labels, activation = \"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=config.loss_function, metrics = [\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_gen, validation_data=test_gen, epochs=config.epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#run.join()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
