{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Caricare i video\n",
    "- Preprocessing dei video (resize e normalizzazione)\n",
    "- Split train test\n",
    "- Estrazione features con CNN\n",
    "- passaggio features a LSTM per classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wp8.pre_processing.utils import listdir_nohidden_sorted as lsdir\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from my_generators import TimeSeriesGenerator as TSG\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"../outputs/dataset/features/\"\n",
    "dataset_path = \"../outputs/dataset/dataset/\"\n",
    "\n",
    "#load features\n",
    "all_features = []\n",
    "all_features_paths = lsdir(features_path)[0:1]\n",
    "for _, feature_file in enumerate(tqdm(all_features_paths)):\n",
    "  with np.load(feature_file) as features:\n",
    "      all_features.append(features[\"arr_0\"])\n",
    "      \n",
    "all_features=np.concatenate(all_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for _,filename in enumerate(tqdm(lsdir(dataset_path)[0:1])):\n",
    "  df = pd.read_csv(filename, index_col=0)\n",
    "  dfs.append(df)\n",
    "\n",
    "dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save full dataset and features\n",
    "# ssd_path = \"/Volumes/SSD 1TB 1/Alt Frailty WP8/DATASET_processed\"\n",
    "# dataset.to_csv(f\"{ssd_path}/dataset.csv\")\n",
    "\n",
    "# np.save(f\"{ssd_path}/features\", all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape, all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dataset[\"frame_name\"]\n",
    "cams = []\n",
    "for name in names:\n",
    "  cams.append(int(name[-6]))\n",
    "\n",
    "dataset[\"cams\"] = pd.Series(cams)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"features\"] = pd.Series(all_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"features\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count samples per label\n",
    "dataset[\"micro_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape = (dataset[\"features\"].shape[0], 2048)\n",
    "features = np.array(dataset[\"features\"].to_list())\n",
    "type(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# batch = (features, le.fit_transform(dataset[\"micro_labels\"]), dataset[\"cams\"].tolist())\n",
    "# gen = TSG(X = batch[0], y = batch[1], cams=batch[2], num_features=2048, batch_size=32, stride=10, seq_len = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "encoded_labels = le.fit_transform(dataset[\"micro_labels\"])\n",
    "n_labels = len(np.unique(encoded_labels))\n",
    "print(n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "log_folder = \"../logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback=TensorBoard(log_dir=log_folder)\n",
    "\n",
    "gen = TSG(X=features, y = encoded_labels, num_features=2048, cams=dataset[\"cams\"].tolist(), batch_size = 32, stride=20, seq_len = 20)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(20, 2048)))\n",
    "model.add(Dense(n_labels, activation = \"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "history=model.fit(gen, epochs=1, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir log_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
