{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluating models on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wp8.pre_processing.utils import listdir_nohidden_sorted as lsdir\n",
    "from wp8.pre_processing.utils import safe_mkdir\n",
    "from tqdm.notebook import tqdm\n",
    "from wp8.pre_processing.generators import TimeSeriesGenerator as TSG\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mode\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Accuracy, SparseCategoricalAccuracy, Recall, Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreaapi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %env WANDB_API_KEY=$a22c5c63cb14ecd62db2141ec9ca69d588a6483e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4216b59bd1d64d72a0d1c6eee322aad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_path = \"../outputs/dataset/features/\"\n",
    "dataset_path = \"../outputs/dataset/dataset/\"\n",
    "\n",
    "# load features\n",
    "all_features = []\n",
    "all_features_paths = lsdir(features_path)\n",
    "for _, feature_file in enumerate(tqdm(all_features_paths)):\n",
    "    with np.load(feature_file) as features:\n",
    "        all_features.append(features[\"arr_0\"])\n",
    "\n",
    "all_features = np.concatenate(all_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d91bc96ceae4e31af95f83721d4a4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for _, filename in enumerate(tqdm(lsdir(dataset_path))):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    dfs.append(df)\n",
    "\n",
    "dataset = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30240, 4) (30240, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape, all_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_7_4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_7_4306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30227</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_7_4307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30228</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_7_4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30229</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_7_4309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30230 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      micro_labels macro_labels            ar_labels              frame_name\n",
       "0        lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0000\n",
       "1        lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0001\n",
       "2        lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0002\n",
       "3        lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0003\n",
       "4        lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0004\n",
       "...            ...          ...                  ...                     ...\n",
       "30225    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_7_4305\n",
       "30226    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_7_4306\n",
       "30227    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_7_4307\n",
       "30228    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_7_4308\n",
       "30229    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_7_4309\n",
       "\n",
       "[30230 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_labels</th>\n",
       "      <th>macro_labels</th>\n",
       "      <th>ar_labels</th>\n",
       "      <th>frame_name</th>\n",
       "      <th>cams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lie_still</td>\n",
       "      <td>lying_down</td>\n",
       "      <td>actor_repositioning</td>\n",
       "      <td>actor_1_bed_cam_1_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_labels macro_labels            ar_labels              frame_name  cams\n",
       "0    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0000     1\n",
       "1    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0001     1\n",
       "2    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0002     1\n",
       "3    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0003     1\n",
       "4    lie_still   lying_down  actor_repositioning  actor_1_bed_cam_1_0004     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = dataset[\"frame_name\"]\n",
    "cams = []\n",
    "for name in names:\n",
    "    cams.append(int(name[-6]))\n",
    "\n",
    "dataset[\"cams\"] = pd.Series(cams)\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_labels:  12\n"
     ]
    }
   ],
   "source": [
    "# count samples per label, get labels names, encode labels to integers\n",
    "dataset[\"micro_labels\"].value_counts()\n",
    "micro_labels_names = dataset[\"micro_labels\"].unique().tolist()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoded_labels = le.fit_transform(dataset[\"micro_labels\"])\n",
    "n_labels = len(np.unique(encoded_labels))\n",
    "print(\"n_labels: \", n_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lie_still',\n",
       " 'sit_up_from_lying',\n",
       " 'stand_up_from_sit',\n",
       " 'stand_still',\n",
       " 'sit_down_from_standing',\n",
       " 'lie_down_from_sitting',\n",
       " 'fall_frontal',\n",
       " 'lie_down_on_the_floor',\n",
       " 'stand_up_from_floor',\n",
       " 'fall_lateral',\n",
       " 'sit_still',\n",
       " 'fall_crouch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(micro_labels_names)\n",
    "micro_labels_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANDB project initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andrea/Documents/Github/WP8_refactoring/wp8/notebooks/wandb/run-20220515_171506-37hink8x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/37hink8x\" target=\"_blank\">young-dream-5</a></strong> to <a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"Fall detection CNN + RNN\",\n",
    "    config={\n",
    "        \"model\": \"LSTM\",\n",
    "        \"epochs\": 5,\n",
    "        \"sequence_length\": 20,\n",
    "        \"num_features\": 2048,\n",
    "        \"batch_size\": 40,\n",
    "        \"sliding_window_stride\": 10,\n",
    "        \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "        \"architecture\": \"LSTM\",\n",
    "        \"dataset\": \"Actor_1_Bed\",\n",
    "        \"dropout\": 0.8,\n",
    "        \"lstm1_units\": 32,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"split_ratio\": 0.7\n",
    "    },\n",
    ")\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :(21168, 2048), y_train shape: (21168,), X_test shape: (9072, 2048), y_test shape: (9072,)\n"
     ]
    }
   ],
   "source": [
    "split = int(dataset.shape[0] * config.split_ratio)\n",
    "X_train = np.array(dataset[\"features\"][0:split].tolist())\n",
    "X_test = np.array(dataset[\"features\"][split:].tolist())\n",
    "\n",
    "y_train = encoded_labels[0:split]\n",
    "y_test = encoded_labels[split:]\n",
    "\n",
    "cams_train = dataset[\"cams\"][0:split]\n",
    "cams_test = dataset[\"cams\"][split:]\n",
    "\n",
    "print(f\"X_train shape :{X_train.shape}, y_train shape: {y_train.shape}, X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last train frame: actor_1_bed_cam_5_3888\n",
      "First test frame: actor_1_bed_cam_5_3889\n"
     ]
    }
   ],
   "source": [
    "print(f'Last train frame: {dataset[\"frame_name\"][split]}\\nFirst test frame: {dataset[\"frame_name\"][split+1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                266368    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,764\n",
      "Trainable params: 266,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:15:14.616719: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-15 17:15:14.616849: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_gen = TSG(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    num_features=config.num_features,\n",
    "    cams=cams_train.tolist(),\n",
    "    batch_size=config.batch_size,\n",
    "    stride=config.sliding_window_stride,\n",
    "    seq_len=config.sequence_length,\n",
    ")\n",
    "test_gen = TSG(\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    cams=cams_test.tolist(),\n",
    "    num_features=config.num_features,\n",
    "    batch_size=config.batch_size,\n",
    "    stride=config.sliding_window_stride,\n",
    "    seq_len=config.sequence_length,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=config.lstm1_units, input_shape=(20, config.num_features)))\n",
    "model.add(Dropout(config.dropout))\n",
    "model.add(Dense(n_labels, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "    loss=config.loss_function,\n",
    "    metrics=[\"accuracy\",\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "dir_path = f\"experiments/model_checkpoint/{config.model}_{config.dataset}\"\n",
    "safe_mkdir(dir_path)\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y_%H:%M:%S\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f\"{dir_path}/{config.model}_{dt_string}\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "callbacks = [WandbCallback(), model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:15:18.650777: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-15 17:15:19.062505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-15 17:15:19.191267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/529 [..............................] - ETA: 8s - loss: 5.3251 - acc: 0.1667 - sparse_categorical_accuracy: 0.1667  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:15:19.358343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/529 [============================>.] - ETA: 0s - loss: 2.2219 - acc: 0.3930 - sparse_categorical_accuracy: 0.3930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:15:26.440739: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-15 17:15:26.489767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "529/529 [==============================] - 9s 16ms/step - loss: 2.2275 - acc: 0.3926 - sparse_categorical_accuracy: 0.3926 - val_loss: 2.3218 - val_acc: 0.1431 - val_sparse_categorical_accuracy: 0.1431 - _timestamp: 1652627728.0000 - _runtime: 22.0000\n",
      "Epoch 2/5\n",
      "527/529 [============================>.] - ETA: 0s - loss: 2.0647 - acc: 0.3941 - sparse_categorical_accuracy: 0.3941WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "529/529 [==============================] - 8s 16ms/step - loss: 2.0709 - acc: 0.3926 - sparse_categorical_accuracy: 0.3926 - val_loss: 2.3083 - val_acc: 0.1062 - val_sparse_categorical_accuracy: 0.1062 - _timestamp: 1652627736.0000 - _runtime: 30.0000\n",
      "Epoch 3/5\n",
      "525/529 [============================>.] - ETA: 0s - loss: 2.0908 - acc: 0.3981 - sparse_categorical_accuracy: 0.3981WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "529/529 [==============================] - 8s 16ms/step - loss: 2.0885 - acc: 0.3989 - sparse_categorical_accuracy: 0.3989 - val_loss: 2.2221 - val_acc: 0.1062 - val_sparse_categorical_accuracy: 0.1062 - _timestamp: 1652627744.0000 - _runtime: 38.0000\n",
      "Epoch 4/5\n",
      "529/529 [==============================] - ETA: 0s - loss: 2.0841 - acc: 0.3976 - sparse_categorical_accuracy: 0.3976WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "529/529 [==============================] - 9s 17ms/step - loss: 2.0841 - acc: 0.3976 - sparse_categorical_accuracy: 0.3976 - val_loss: 2.3588 - val_acc: 0.1032 - val_sparse_categorical_accuracy: 0.1032 - _timestamp: 1652627753.0000 - _runtime: 47.0000\n",
      "Epoch 5/5\n",
      "528/529 [============================>.] - ETA: 0s - loss: 2.0667 - acc: 0.4059 - sparse_categorical_accuracy: 0.4059WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "529/529 [==============================] - 8s 16ms/step - loss: 2.0673 - acc: 0.4052 - sparse_categorical_accuracy: 0.4052 - val_loss: 2.1695 - val_acc: 0.1062 - val_sparse_categorical_accuracy: 0.1062 - _timestamp: 1652627762.0000 - _runtime: 56.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, validation_data=test_gen, epochs=config.epochs, callbacks=callbacks)\n",
    "test_gen.evaluate = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/d1_5tcmd7c52fnmphb0d7q0w0000gn/T/ipykernel_10842/4234606000.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  test_logits = model.predict_generator(test_gen, verbose=1)\n",
      "2022-05-15 17:16:02.242771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-15 17:16:02.281972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test_logits = model.predict_generator(test_gen, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_gen.n_windows: 3\n",
      "\n",
      "test_gen series_labels length: 3393\n",
      "\n",
      "Correct number of labels: 678\n",
      "\n",
      "logits shape: (678, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"test_gen.n_windows: {test_gen.n_windows}\\n\\ntest_gen series_labels length: {len(test_gen.series_labels)}\\n\\nCorrect number of labels: {test_gen.n_windows * (y_test.shape[0] // test_gen.batch_size)}\\n\\nlogits shape: {test_logits.shape}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_series_labels(timestep_labels: list, n_batches: int, n_windows: int, seq_len: int, stride: int) -> list:\n",
    "    series_labels = []\n",
    "    for w in range(n_windows * n_batches):\n",
    "        s = w * stride\n",
    "        labels_seq = timestep_labels[s : s + seq_len]\n",
    "        series_labels.append(mode(labels_seq))\n",
    "    return series_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_classes = np.argmax(test_logits, axis=1).tolist()\n",
    "y_train_series = to_series_labels(\n",
    "    y_train,\n",
    "    train_gen.n_batches,\n",
    "    train_gen.n_windows,\n",
    "    train_gen.seq_len,\n",
    "    train_gen.stride,\n",
    ")\n",
    "y_test_series = to_series_labels(y_test, test_gen.n_batches, test_gen.n_windows, test_gen.seq_len, test_gen.stride)\n",
    "wandb.sklearn.plot_roc(y_test_series, test_logits, micro_labels_names)\n",
    "wandb.sklearn.plot_class_proportions(y_train_series, y_test_series, micro_labels_names)\n",
    "wandb.sklearn.plot_precision_recall(y_test_series, test_logits, micro_labels_names)\n",
    "wandb.sklearn.plot_confusion_matrix(y_test_series, y_pred_test_classes, micro_labels_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7c779864a04d37aeba798427be27d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.143 MB of 3.149 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.998097…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▅▄█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▁▂▂▁</td></tr><tr><td>sparse_categorical_accuracy</td><td>▁▁▅▄█</td></tr><tr><td>val_acc</td><td>█▂▂▁▂</td></tr><tr><td>val_loss</td><td>▇▆▃█▁</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>█▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.40517</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>2.16952</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>2.06734</td></tr><tr><td>sparse_categorical_accuracy</td><td>0.40517</td></tr><tr><td>val_acc</td><td>0.10619</td></tr><tr><td>val_loss</td><td>2.16952</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>0.10619</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-dream-5</strong>: <a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/37hink8x\" target=\"_blank\">https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/37hink8x</a><br/>Synced 6 W&B file(s), 5 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220515_171506-37hink8x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.join()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
