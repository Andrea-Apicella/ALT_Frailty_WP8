{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# Evaluating CNN+RNN models on the dataset\n",
    "\n",
    "# Imports\n",
    "import gc\n",
    "import os, random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import wandb\n",
    "from wp8.pre_processing.utils import safe_mkdir\n",
    "from wp8.utils.cnn_rnn_utils import load_and_split\n",
    "from wp8.utils.dataset import TimeSeriesGenerator as TSG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict(\n",
    "    {\n",
    "        \"lstm1_units\": 16,\n",
    "        \"lstm2_units\": 8,\n",
    "        \"dense_units\": 8,\n",
    "        \"dropout\": 0.4,\n",
    "        \"epochs\": 1000,\n",
    "        \"train_actors\": [1, 2, 3],\n",
    "        \"val_actors\": [4],\n",
    "        \"train_cams\": [1, 2, 3,4,5,6,7],\n",
    "        \"val_cams\": [1],\n",
    "        \"seq_len\": 20,\n",
    "        \"split_ratio\": None,\n",
    "        \"drop_offair\": True,\n",
    "        \"undersample\": False,\n",
    "        \"batch_size\": 32,\n",
    "        \"stride\": 10,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"micro_classes\": False,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Load Train Set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7e6ddcc02f4c6d86a19f31e9d4fa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e00095cdc0f4c27adb89131d721feda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading csv datasets:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Load Val Set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e88fbdb54f4710bfb77d0af442a308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536b9d4c3060447cbd0949084fc58c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading csv datasets:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (346738, 2048), len y_train: 346738, X_val shape: (5624, 2048), len y_val: 5624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, cams_train, cams_val = load_and_split(\n",
    "    opt.train_actors, opt.val_actors, opt.train_cams, opt.val_cams, opt.split_ratio, opt.drop_offair, opt.undersample, opt.micro_classes\n",
    ")\n",
    "print(f\"\\nX_train shape: {X_train.shape}, len y_train: {len(y_train)}, X_val shape: {X_val.shape}, len y_val: {len(y_val)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting in Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511610530c724615897c5c8261caf848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapping:\n",
      "{'adl': 1, 'falling': 2, 'lying_down': 3}\n",
      "\n",
      "Class distribution:\n",
      "Counter({'adl': 24433, 'falling': 6903, 'lying_down': 3336})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81495fac8947cda6f1b23b40d500f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train_series shape: (34672, 20, 2048), len y_train_series: 34672, X_val_series shape: (561, 20, 2048), len y_val_series: 561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "series_gen = TSG(opt)\n",
    "X_train_series, y_train_series, distrib, classes = series_gen.get_train_series(X_train, y_train, cams_train)\n",
    "X_val_series, y_val_series = series_gen.get_val_series(X_val, y_val, cams_val)\n",
    "print(f\"\\nX_train_series shape: {X_train_series.shape}, len y_train_series: {len(y_train_series)}, X_val_series shape: {X_val_series.shape}, len y_val_series: {len(y_val_series)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling - y_train_series shape: [(0, 24433), (1, 6903), (2, 3336)]\n",
      "lie_down_samples: 6903\n",
      "adl_samples: 24433\n",
      "fall_samples: 3336\n"
     ]
    }
   ],
   "source": [
    "distrib = Counter(y_train_series).most_common()\n",
    "print(f\"Before resampling - y_train_series shape: {distrib}\")\n",
    "\n",
    "adl_samples, lie_down_samples, fall_samples = distrib[0][1], distrib[1][1], distrib[2][1]\n",
    "\n",
    "print(f\"lie_down_samples: {lie_down_samples}\\nadl_samples: {adl_samples}\\nfall_samples: {fall_samples}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "#from imblearn.combine import SMOTETomek\n",
    "\n",
    "#res_ratio = int(fall_samples*1.5)\n",
    "\n",
    "#undersampling_strategy = {0: res_ratio, 2: res_ratio, 1: res_ratio}\n",
    "undersampling_strategy = \"not minority\"\n",
    "oversampling_strategy = {0: adl_samples, 1: int(lie_down_samples * 1.1), 2: int(fall_samples*1.2)}\n",
    "\n",
    "under = RandomUnderSampler(random_state=2, sampling_strategy=undersampling_strategy)\n",
    "#nearmiss = NearMiss(version=3, sampling_strategy=undersampling_strategy)\n",
    "#over = RandomOverSampler(random_state=2, sampling_strategy=oversampling_strategy)\n",
    "\n",
    "smote = SMOTE(random_state=2, sampling_strategy=oversampling_strategy, n_jobs=-1)\n",
    "\n",
    "#steps = [(\"o\", over), (\"u\", under)]\n",
    "#steps = [(\"smote\", smote), (\"u\", under)]\n",
    "steps = [(\"oversample\", smote),(\"undersample\", under)]\n",
    "pipeline = Pipeline(steps=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_train_series shape: (34672, 20, 2048)\n",
      "X_train_series reshaped: (34672, 40960)\n",
      "After resampling X_train_series shape: (12009, 20, 2048)\n",
      "After resampling - y_train_series count: Counter({0: 4003, 1: 4003, 2: 4003})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original X_train_series shape: {X_train_series.shape}\")\n",
    "\n",
    "X_train_series = np.reshape(X_train_series, (-1, 20 * 2048))\n",
    "print(f\"X_train_series reshaped: {X_train_series.shape}\")\n",
    "\n",
    "X_train_series, y_train_series = pipeline.fit_resample(X_train_series, y_train_series)\n",
    "\n",
    "X_train_series = np.reshape(X_train_series, (-1, 20, 2048))\n",
    "\n",
    "print(f\"After resampling X_train_series shape: {X_train_series.shape}\")\n",
    "print(f\"After resampling - y_train_series count: {Counter(y_train_series)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreaapi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/users/andreaap/ALT_Frailty_WP8/wp8/wandb/run-20220610_181658-21ew9xe5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN/runs/21ew9xe5\" target=\"_blank\">toasty-rain-116</a></strong> to <a href=\"https://wandb.ai/andreaapi/Fall%20detection%20CNN%20%2B%20RNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB project initialization\n",
    "run = wandb.init(\n",
    "    project=\"Fall detection CNN + RNN\",\n",
    "    config={\n",
    "        \"model\": \"LSTM\",\n",
    "        \"epochs\": opt.epochs,\n",
    "        \"seq_len\": opt.seq_len,\n",
    "        \"num_features\": 2048,\n",
    "        \"batch_size\": opt.batch_size,\n",
    "        \"stride\": opt.stride,\n",
    "        \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "        \"architecture\": \"LSTM\",\n",
    "        \"train_actors\": opt.train_actors,\n",
    "        \"val_actors\": opt.val_actors,\n",
    "        \"train_cams\": opt.train_cams,\n",
    "        \"val_cams\": opt.val_cams,\n",
    "        \"micro_classes\": opt.classes,\n",
    "        \"dropout\": opt.dropout,\n",
    "        \"lstm1_units\": opt.lstm1_units,\n",
    "        \"lstm2_units\": opt.lstm2_units,\n",
    "        \"dense_units\": opt.dense_units,\n",
    "        \"learning_rate\": opt.learning_rate,\n",
    "        \"split_ratio\": opt.split_ratio,\n",
    "        \"drop_offair\": opt.drop_offair,\n",
    "        \"undersample\": opt.undersample,\n",
    "    },\n",
    ")\n",
    "\n",
    "cfg = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 18:17:04.789841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:04.794165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:04.794360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:04.794938: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-10 18:17:04.796820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:04.796994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:04.797155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:05.162717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:05.162926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:05.163087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 18:17:05.163226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22291 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 16)            132160    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 16)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 800       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,059\n",
      "Trainable params: 133,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=cfg.lstm1_units, input_shape=(cfg.seq_len, cfg.num_features), return_sequences=True))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(LSTM(units=cfg.lstm2_units, input_shape=(cfg.seq_len, cfg.num_features), return_sequences=False))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(Dense(units=cfg.dense_units, activation=\"relu\"))\n",
    "model.add(Dropout(cfg.dropout))\n",
    "model.add(Dense(units=np.unique(y_train_series, axis=0).shape[0], activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "    loss=cfg.loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "dir_path = f\"model_checkpoints\"\n",
    "safe_mkdir(dir_path)\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f\"{dir_path}/{cfg.model}_{dt_string}\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    initial_value_threshold=0.8,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    min_delta=1e-5,\n",
    "    cooldown=1,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "callbacks = [WandbCallback(), model_checkpoint, reduce_lr, early_stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 18:17:11.997533: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/376 [..............................] - ETA: 1s - loss: 1.0982 - accuracy: 0.3385   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 18:17:12.521436: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366/376 [============================>.] - ETA: 0s - loss: 1.0983 - accuracy: 0.3160\n",
      "Epoch 00001: val_loss improved from inf to 1.09217, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 5s 6ms/step - loss: 1.0983 - accuracy: 0.3167 - val_loss: 1.0922 - val_accuracy: 0.3636 - _timestamp: 1654877834.0000 - _runtime: 16.0000 - lr: 1.0000e-05\n",
      "Epoch 2/1000\n",
      "373/376 [============================>.] - ETA: 0s - loss: 1.0963 - accuracy: 0.3254\n",
      "Epoch 00002: val_loss improved from 1.09217 to 1.09182, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0963 - accuracy: 0.3253 - val_loss: 1.0918 - val_accuracy: 0.3850 - _timestamp: 1654877836.0000 - _runtime: 18.0000 - lr: 1.0000e-05\n",
      "Epoch 3/1000\n",
      "367/376 [============================>.] - ETA: 0s - loss: 1.0948 - accuracy: 0.3340\n",
      "Epoch 00003: val_loss improved from 1.09182 to 1.09030, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0948 - accuracy: 0.3348 - val_loss: 1.0903 - val_accuracy: 0.3155 - _timestamp: 1654877838.0000 - _runtime: 20.0000 - lr: 1.0000e-05\n",
      "Epoch 4/1000\n",
      "374/376 [============================>.] - ETA: 0s - loss: 1.0929 - accuracy: 0.3417\n",
      "Epoch 00004: val_loss improved from 1.09030 to 1.08892, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0929 - accuracy: 0.3422 - val_loss: 1.0889 - val_accuracy: 0.3387 - _timestamp: 1654877840.0000 - _runtime: 22.0000 - lr: 1.0000e-05\n",
      "Epoch 5/1000\n",
      "373/376 [============================>.] - ETA: 0s - loss: 1.0896 - accuracy: 0.3471\n",
      "Epoch 00005: val_loss improved from 1.08892 to 1.08774, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0896 - accuracy: 0.3472 - val_loss: 1.0877 - val_accuracy: 0.3209 - _timestamp: 1654877842.0000 - _runtime: 24.0000 - lr: 1.0000e-05\n",
      "Epoch 6/1000\n",
      "367/376 [============================>.] - ETA: 0s - loss: 1.0843 - accuracy: 0.3457\n",
      "Epoch 00006: val_loss improved from 1.08774 to 1.08284, saving model to model_checkpoints/LSTM_10-06-2022_18:17:05\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0841 - accuracy: 0.3457 - val_loss: 1.0828 - val_accuracy: 0.3030 - _timestamp: 1654877844.0000 - _runtime: 26.0000 - lr: 1.0000e-05\n",
      "Epoch 7/1000\n",
      "369/376 [============================>.] - ETA: 0s - loss: 1.0768 - accuracy: 0.3681\n",
      "Epoch 00007: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0770 - accuracy: 0.3674 - val_loss: 1.0850 - val_accuracy: 0.3708 - _timestamp: 1654877846.0000 - _runtime: 28.0000 - lr: 1.0000e-05\n",
      "Epoch 8/1000\n",
      "367/376 [============================>.] - ETA: 0s - loss: 1.0693 - accuracy: 0.3707\n",
      "Epoch 00008: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0696 - accuracy: 0.3703 - val_loss: 1.0833 - val_accuracy: 0.1925 - _timestamp: 1654877848.0000 - _runtime: 30.0000 - lr: 1.0000e-05\n",
      "Epoch 9/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0621 - accuracy: 0.3785\n",
      "Epoch 00009: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0625 - accuracy: 0.3779 - val_loss: 1.0830 - val_accuracy: 0.1640 - _timestamp: 1654877850.0000 - _runtime: 32.0000 - lr: 1.0000e-05\n",
      "Epoch 10/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0570 - accuracy: 0.3905\n",
      "Epoch 00010: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0566 - accuracy: 0.3906 - val_loss: 1.0875 - val_accuracy: 0.1640 - _timestamp: 1654877851.0000 - _runtime: 33.0000 - lr: 1.0000e-05\n",
      "Epoch 11/1000\n",
      "365/376 [============================>.] - ETA: 0s - loss: 1.0500 - accuracy: 0.3956\n",
      "Epoch 00011: val_loss did not improve from 1.08284\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0499 - accuracy: 0.3966 - val_loss: 1.0943 - val_accuracy: 0.1765 - _timestamp: 1654877853.0000 - _runtime: 35.0000 - lr: 1.0000e-05\n",
      "Epoch 12/1000\n",
      "372/376 [============================>.] - ETA: 0s - loss: 1.0455 - accuracy: 0.3994\n",
      "Epoch 00012: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0455 - accuracy: 0.3995 - val_loss: 1.0909 - val_accuracy: 0.1676 - _timestamp: 1654877855.0000 - _runtime: 37.0000 - lr: 1.0000e-06\n",
      "Epoch 13/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0454 - accuracy: 0.4000\n",
      "Epoch 00013: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0455 - accuracy: 0.3998 - val_loss: 1.0894 - val_accuracy: 0.1729 - _timestamp: 1654877857.0000 - _runtime: 39.0000 - lr: 1.0000e-06\n",
      "Epoch 14/1000\n",
      "371/376 [============================>.] - ETA: 0s - loss: 1.0459 - accuracy: 0.3982\n",
      "Epoch 00014: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0459 - accuracy: 0.3981 - val_loss: 1.0906 - val_accuracy: 0.1693 - _timestamp: 1654877859.0000 - _runtime: 41.0000 - lr: 1.0000e-06\n",
      "Epoch 15/1000\n",
      "375/376 [============================>.] - ETA: 0s - loss: 1.0441 - accuracy: 0.4033\n",
      "Epoch 00015: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0440 - accuracy: 0.4034 - val_loss: 1.0910 - val_accuracy: 0.1640 - _timestamp: 1654877861.0000 - _runtime: 43.0000 - lr: 1.0000e-06\n",
      "Epoch 16/1000\n",
      "368/376 [============================>.] - ETA: 0s - loss: 1.0457 - accuracy: 0.3960\n",
      "Epoch 00016: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0456 - accuracy: 0.3970 - val_loss: 1.0912 - val_accuracy: 0.1676 - _timestamp: 1654877863.0000 - _runtime: 45.0000 - lr: 1.0000e-06\n",
      "Epoch 17/1000\n",
      "369/376 [============================>.] - ETA: 0s - loss: 1.0447 - accuracy: 0.4028\n",
      "Epoch 00017: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0448 - accuracy: 0.4024 - val_loss: 1.0914 - val_accuracy: 0.1676 - _timestamp: 1654877865.0000 - _runtime: 47.0000 - lr: 1.0000e-06\n",
      "Epoch 18/1000\n",
      "368/376 [============================>.] - ETA: 0s - loss: 1.0430 - accuracy: 0.4040\n",
      "Epoch 00018: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0435 - accuracy: 0.4034 - val_loss: 1.0911 - val_accuracy: 0.1729 - _timestamp: 1654877866.0000 - _runtime: 48.0000 - lr: 1.0000e-06\n",
      "Epoch 19/1000\n",
      "367/376 [============================>.] - ETA: 0s - loss: 1.0423 - accuracy: 0.4092\n",
      "Epoch 00019: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0424 - accuracy: 0.4089 - val_loss: 1.0915 - val_accuracy: 0.1676 - _timestamp: 1654877868.0000 - _runtime: 50.0000 - lr: 1.0000e-06\n",
      "Epoch 20/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0416 - accuracy: 0.4140\n",
      "Epoch 00020: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0418 - accuracy: 0.4131 - val_loss: 1.0922 - val_accuracy: 0.1747 - _timestamp: 1654877870.0000 - _runtime: 52.0000 - lr: 1.0000e-06\n",
      "Epoch 21/1000\n",
      "371/376 [============================>.] - ETA: 0s - loss: 1.0430 - accuracy: 0.3991\n",
      "Epoch 00021: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0428 - accuracy: 0.3990 - val_loss: 1.0915 - val_accuracy: 0.1729 - _timestamp: 1654877872.0000 - _runtime: 54.0000 - lr: 1.0000e-06\n",
      "Epoch 22/1000\n",
      "376/376 [==============================] - ETA: 0s - loss: 1.0402 - accuracy: 0.4036\n",
      "Epoch 00022: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0402 - accuracy: 0.4036 - val_loss: 1.0928 - val_accuracy: 0.1765 - _timestamp: 1654877874.0000 - _runtime: 56.0000 - lr: 1.0000e-06\n",
      "Epoch 23/1000\n",
      "368/376 [============================>.] - ETA: 0s - loss: 1.0393 - accuracy: 0.4051\n",
      "Epoch 00023: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0393 - accuracy: 0.4056 - val_loss: 1.0927 - val_accuracy: 0.1783 - _timestamp: 1654877876.0000 - _runtime: 58.0000 - lr: 1.0000e-06\n",
      "Epoch 24/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0406 - accuracy: 0.4014\n",
      "Epoch 00024: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0404 - accuracy: 0.4016 - val_loss: 1.0935 - val_accuracy: 0.1800 - _timestamp: 1654877878.0000 - _runtime: 60.0000 - lr: 1.0000e-06\n",
      "Epoch 25/1000\n",
      "368/376 [============================>.] - ETA: 0s - loss: 1.0400 - accuracy: 0.3989\n",
      "Epoch 00025: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0402 - accuracy: 0.3995 - val_loss: 1.0941 - val_accuracy: 0.1800 - _timestamp: 1654877880.0000 - _runtime: 62.0000 - lr: 1.0000e-06\n",
      "Epoch 26/1000\n",
      "370/376 [============================>.] - ETA: 0s - loss: 1.0402 - accuracy: 0.4024\n",
      "Epoch 00026: val_loss did not improve from 1.08284\n",
      "376/376 [==============================] - 2s 5ms/step - loss: 1.0399 - accuracy: 0.4039 - val_loss: 1.0944 - val_accuracy: 0.1783 - _timestamp: 1654877882.0000 - _runtime: 64.0000 - lr: 1.0000e-06\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(X_train_series, y_train_series, validation_data=(X_val_series, y_val_series), epochs=cfg.epochs, callbacks=callbacks, batch_size=cfg.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "val_logits = model.predict(X_val_series, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2526"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up memory\n",
    "del X_train_series\n",
    "del X_val_series\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_val_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cr \u001b[38;5;241m=\u001b[39m classification_report(y_val_series, \u001b[43my_pred_val_classes\u001b[49m, target_names\u001b[38;5;241m=\u001b[39mclasses)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_val_classes' is not defined"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_val_series, y_pred_val_classes, target_names=classes)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log metrics to wandb\n",
    "y_pred_val_classes = np.argmax(val_logits, axis=1).tolist()\n",
    "\n",
    "cr = classification_report(y_val_series, y_pred_val_classes, target_names=classes, output_dict=True)\n",
    "\n",
    "wandb.sklearn.plot_roc(y_val_series, val_logits, classes)\n",
    "wandb.sklearn.plot_class_proportions(y_train_series, y_val_series, classes)\n",
    "wandb.sklearn.plot_precision_recall(y_val_series, val_logits, classes)\n",
    "wandb.sklearn.plot_confusion_matrix(y_val_series, y_pred_val_classes, classes)\n",
    "\n",
    "import pandas as pd\n",
    "cr = pd.DataFrame(cr)\n",
    "cr = table.iloc[:-1, :3].round(2)\n",
    "\n",
    "cr_wandb = wandb.Table(dataFrame = cr)\n",
    "wandb.log({\"Classification report\": cr_wandb})\n",
    "\n",
    "wandb.join()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "045da2998f02dde6c755b0fa2e74d8766d7d056d6163358ab445ad432d6df67f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
